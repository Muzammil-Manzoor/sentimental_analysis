{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sua7Nqn_c-eP",
    "outputId": "0b982e1e-aa40-49d9-de16-0592bf7f93c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Download completed!\n",
      "Extracting dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muzam\\AppData\\Local\\Temp\\ipykernel_22216\\3019950769.py:24: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=extract_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed!\n",
      "Extracted files:\n",
      "./domain_sentiment_data\\sorted_data_acl\\books\\negative.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\books\\positive.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\dvd\\negative.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\dvd\\positive.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\dvd\\unlabeled.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\electronics\\negative.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\electronics\\positive.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\electronics\\unlabeled.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\kitchen_&_housewares\\negative.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\kitchen_&_housewares\\positive.review\n",
      "./domain_sentiment_data\\sorted_data_acl\\kitchen_&_housewares\\unlabeled.review\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://www.cs.jhu.edu/~mdredze/datasets/sentiment/domain_sentiment_data.tar.gz\"\n",
    "\n",
    "# File name for the downloaded dataset\n",
    "dataset_file = \"domain_sentiment_data.tar.gz\"\n",
    "\n",
    "# Directory to extract the dataset\n",
    "extract_dir = \"./domain_sentiment_data\"\n",
    "\n",
    "# Step 1: Download the dataset\n",
    "if not os.path.exists(dataset_file):\n",
    "    print(\"Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(url, dataset_file)\n",
    "    print(\"Download completed!\")\n",
    "\n",
    "# Step 2: Extract the dataset\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(\"Extracting dataset...\")\n",
    "    with tarfile.open(dataset_file, \"r:gz\") as tar:\n",
    "        tar.extractall(path=extract_dir)\n",
    "    print(\"Extraction completed!\")\n",
    "\n",
    "# Step 3: List the extracted files\n",
    "print(\"Extracted files:\")\n",
    "for root, dirs, files in os.walk(extract_dir):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2whHVPygBR3",
    "outputId": "7c70e48d-1353-4c4f-8eee-2f3f1c78ba85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from positive reviews (books):\n",
      "['<review>\\n', '<unique_id>\\n', '0785758968:one_of_the_best_crichton_novels:joseph_m\\n', '</unique_id>\\n', '<asin>\\n']\n"
     ]
    }
   ],
   "source": [
    "# Load a sample review file (e.g., books/positive.review)\n",
    "file_path = \"./domain_sentiment_data/sorted_data_acl/books/positive.review\"\n",
    "\n",
    "# Read and display the content\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Display the first few lines\n",
    "print(\"Sample data from positive reviews (books):\")\n",
    "print(data[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDiOhdiTlJb8",
    "outputId": "312c9aaa-e0e5-42a7-bc96-be4d02332f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining positive reviews...\n",
      "Combining negative reviews...\n",
      "Shuffling and combining positive and negative reviews...\n",
      "Final combined dataset saved to 'final_reviews.txt'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Define paths to the review files\n",
    "review_files = {\n",
    "    \"positive\": [\n",
    "        \"./domain_sentiment_data/sorted_data_acl/books/positive.review\",\n",
    "        \"./domain_sentiment_data/sorted_data_acl/electronics/positive.review\",\n",
    "        \"./domain_sentiment_data/sorted_data_acl/kitchen_&_housewares/positive.review\",\n",
    "        \"./domain_sentiment_data/sorted_data_acl/dvd/positive.review\"\n",
    "    ],\n",
    "    \"negative\": [\n",
    "        \"./domain_sentiment_data/sorted_data_acl/books/negative.review\",\n",
    "        \"./domain_sentiment_data/sorted_data_acl/electronics/negative.review\",\n",
    "        \"./domain_sentiment_data/sorted_data_acl/kitchen_&_housewares/negative.review\",\n",
    "        \"./domain_sentiment_data/sorted_data_acl/dvd/negative.review\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to combine reviews into a single file\n",
    "def combine_reviews(file_paths, output_file):\n",
    "    combined_reviews = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            combined_reviews.extend(file.readlines())\n",
    "    # Save combined reviews to a file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(combined_reviews)\n",
    "    return combined_reviews\n",
    "\n",
    "# Combine positive reviews\n",
    "print(\"Combining positive reviews...\")\n",
    "positive_reviews = combine_reviews(review_files[\"positive\"], \"all_positive_reviews.txt\")\n",
    "\n",
    "# Combine negative reviews\n",
    "print(\"Combining negative reviews...\")\n",
    "negative_reviews = combine_reviews(review_files[\"negative\"], \"all_negative_reviews.txt\")\n",
    "\n",
    "# Combine both positive and negative reviews randomly\n",
    "print(\"Shuffling and combining positive and negative reviews...\")\n",
    "final_reviews = [(review.strip(), \"positive\") for review in positive_reviews] + \\\n",
    "                [(review.strip(), \"negative\") for review in negative_reviews]\n",
    "random.shuffle(final_reviews)\n",
    "\n",
    "# Save the final shuffled dataset to a file\n",
    "with open(\"final_reviews.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for review, label in final_reviews:\n",
    "        file.write(f\"{label}\\t{review}\\n\")\n",
    "\n",
    "print(\"Final combined dataset saved to 'final_reviews.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWluNqmxllFn",
    "outputId": "be5777e1-1f65-4d0d-fa60-3d3d363d0bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows of final_reviews.txt:\n",
      "positive\tjanuary 22 2006\n",
      "positive\toppo opdv971h digital hdready upconverting dvd player electronics\n",
      "negative\t16 of 18\n",
      "positive\tjuly 26 2006\n",
      "positive\t9 of 9\n",
      "negative\tzojirushi cbaa10 sesame seed grinder 45 grams kitchen  housewares\n",
      "negative\tget fit kids vol 1  hustlebustle  move your muscles dvd kristi dear\n",
      "positive\tproduct desciption could be more specific\n",
      "negative\toctober 9 2006\n",
      "positive\tevanston il usa\n",
      "negative\tdecatur ga usa\n",
      "positive\twhen star treks production crew started falling behind in both schedule and budgets during the first season they came up with the brilliant idea of using the unsold the cage pilot as the basis for a two part episode the result one of the most important and brilliant treks ever done\n",
      "negative\tthe number  a completely different way to think about the rest of your life books lee eisenberg\n",
      "positive\tgirl time a celebration of chick flicks bad hair days  and good friends books laura jensen walker\n",
      "positive\ti am very disappointed with this movie the philadelphia experiment that have no english subtitles due to my deafness i was planning to buy this dvd\n",
      "negative\tok the ticket sub plot is resolved and we have\n",
      "positive\ti was suprized when i read the 1 reviewi have had mine for 3 years and had no problemsit has been in the dishwasherput away by my two kidsno cracks no chipscleans up great\n",
      "negative\t3 of 3\n",
      "negative\tgi joe chicago joe chicago\n",
      "positive\tthe reader that keeps with this book will be rewarded the conversations in the book are intelligent the characters and dialogue are real and the descriptions and settings are vivid while the author provides a lengthy disclaimer at the end of the book explaining how the fictional university and town in the book are not based upon yale and new haven it is sometimes hard to believe especially given that the author has been a faculty member at yale law school for over twentyyears this is not to say however that the descriptions in the book of the law school and town are inaccurate rather they may provide quite an accurate description of a town torn between those affiliated with a prestigious university yale and those that are not\n"
     ]
    }
   ],
   "source": [
    "# Path to the final_reviews.txt file\n",
    "file_path = \"D:/Intelligent System/Final_group_Assignment/final_reviews.txt\"\n",
    "\n",
    "# Read and display the first 20 rows\n",
    "print(\"First 20 rows of final_reviews.txt:\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i < 20:  # Print only the first 20 lines\n",
    "            print(line.strip())\n",
    "        else:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9P3sWlzRnpiZ",
    "outputId": "3a0ff086-e2ae-47c9-bb84-9073f7f09678"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_review(review):\n",
    "    # Remove XML/HTML tags\n",
    "    review = re.sub(r\"<.*?>\", \"\", review)\n",
    "    # Remove non-alphanumeric characters except spaces\n",
    "    review = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", review)\n",
    "    # Convert to lowercase\n",
    "    review = review.lower()\n",
    "    # Remove extra whitespace\n",
    "    review = review.strip()\n",
    "    return review\n",
    "\n",
    "# Example usage\n",
    "sample_review = \"<review_text>This is an <b>amazing</b> product!</review_text>\"\n",
    "cleaned_review = preprocess_review(sample_review)\n",
    "print(\"Cleaned Review:\", cleaned_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUUgmdjsnuQd",
    "outputId": "91f1f7e6-9165-4675-d453-33b909ab4363"
   },
   "outputs": [],
   "source": [
    "# Path to the final_reviews.txt file\n",
    "file_path = \"/content/final_reviews.txt\"\n",
    "\n",
    "# Read and display the first 20 rows\n",
    "print(\"First 20 rows of final_reviews.txt:\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i < 20:  # Print only the first 20 lines\n",
    "            print(line.strip())\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pj4K5CaKn-92"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_review(review):\n",
    "    # Remove XML/HTML tags\n",
    "    review = re.sub(r\"<.*?>\", \"\", review)\n",
    "    # Remove non-alphanumeric characters except spaces\n",
    "    review = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", review)\n",
    "    # Convert to lowercase\n",
    "    review = review.lower()\n",
    "    # Remove numerical entries and short strings\n",
    "    if len(review.split()) > 2:  # Retain only reviews with more than 2 words\n",
    "        return review.strip()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYL2Wb3ToGNt",
    "outputId": "dc30c98d-c760-4d1b-8985-5325aebfa4fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning positive reviews...\n",
      "Cleaning negative reviews...\n",
      "Combining and shuffling reviews...\n",
      "Final cleaned dataset saved to 'final_reviews.txt'.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Combine reviews for all products\n",
    "def load_and_clean_reviews(file_paths):\n",
    "    reviews = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                cleaned = preprocess_review(line)\n",
    "                if cleaned:  # Only add cleaned reviews\n",
    "                    reviews.append(cleaned)\n",
    "    return reviews\n",
    "\n",
    "# Define paths for positive and negative reviews\n",
    "positive_paths = [\n",
    "    \"./domain_sentiment_data/sorted_data_acl/books/positive.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/electronics/positive.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/kitchen_&_housewares/positive.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/dvd/positive.review\",\n",
    "]\n",
    "\n",
    "negative_paths = [\n",
    "    \"./domain_sentiment_data/sorted_data_acl/books/negative.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/electronics/negative.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/kitchen_&_housewares/negative.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/dvd/negative.review\",\n",
    "]\n",
    "\n",
    "# Load and clean positive and negative reviews\n",
    "print(\"Cleaning positive reviews...\")\n",
    "positive_reviews = load_and_clean_reviews(positive_paths)\n",
    "print(\"Cleaning negative reviews...\")\n",
    "negative_reviews = load_and_clean_reviews(negative_paths)\n",
    "\n",
    "# Combine and shuffle the reviews\n",
    "print(\"Combining and shuffling reviews...\")\n",
    "final_reviews = [(review, \"positive\") for review in positive_reviews] + \\\n",
    "                [(review, \"negative\") for review in negative_reviews]\n",
    "random.shuffle(final_reviews)\n",
    "\n",
    "# Save the final dataset to a file\n",
    "with open(\"final_reviews.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for review, label in final_reviews:\n",
    "        file.write(f\"{label}\\t{review}\\n\")\n",
    "\n",
    "print(\"Final cleaned dataset saved to 'final_reviews.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sr28dvBdoLJ7",
    "outputId": "bd2e69ec-97d5-4113-b91a-b29f2f54b107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows of final_reviews.txt:\n",
      "positive\tjanuary 22 2006\n",
      "positive\toppo opdv971h digital hdready upconverting dvd player electronics\n",
      "negative\t16 of 18\n",
      "positive\tjuly 26 2006\n",
      "positive\t9 of 9\n",
      "negative\tzojirushi cbaa10 sesame seed grinder 45 grams kitchen  housewares\n",
      "negative\tget fit kids vol 1  hustlebustle  move your muscles dvd kristi dear\n",
      "positive\tproduct desciption could be more specific\n",
      "negative\toctober 9 2006\n",
      "positive\tevanston il usa\n",
      "negative\tdecatur ga usa\n",
      "positive\twhen star treks production crew started falling behind in both schedule and budgets during the first season they came up with the brilliant idea of using the unsold the cage pilot as the basis for a two part episode the result one of the most important and brilliant treks ever done\n",
      "negative\tthe number  a completely different way to think about the rest of your life books lee eisenberg\n",
      "positive\tgirl time a celebration of chick flicks bad hair days  and good friends books laura jensen walker\n",
      "positive\ti am very disappointed with this movie the philadelphia experiment that have no english subtitles due to my deafness i was planning to buy this dvd\n",
      "negative\tok the ticket sub plot is resolved and we have\n",
      "positive\ti was suprized when i read the 1 reviewi have had mine for 3 years and had no problemsit has been in the dishwasherput away by my two kidsno cracks no chipscleans up great\n",
      "negative\t3 of 3\n",
      "negative\tgi joe chicago joe chicago\n",
      "positive\tthe reader that keeps with this book will be rewarded the conversations in the book are intelligent the characters and dialogue are real and the descriptions and settings are vivid while the author provides a lengthy disclaimer at the end of the book explaining how the fictional university and town in the book are not based upon yale and new haven it is sometimes hard to believe especially given that the author has been a faculty member at yale law school for over twentyyears this is not to say however that the descriptions in the book of the law school and town are inaccurate rather they may provide quite an accurate description of a town torn between those affiliated with a prestigious university yale and those that are not\n"
     ]
    }
   ],
   "source": [
    "# Path to the final_reviews.txt file\n",
    "file_path = \"final_reviews.txt\"\n",
    "\n",
    "# Display the first 20 rows\n",
    "print(\"First 20 rows of final_reviews.txt:\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i < 20:  # Print only the first 20 lines\n",
    "            print(line.strip())\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvFOs-zqrkMP",
    "outputId": "d462c050-4dab-48b6-8792-6157cff7bfe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning positive reviews...\n",
      "Cleaning negative reviews...\n",
      "Combining and shuffling reviews...\n",
      "Final dataset saved to final_reviews_cleaned_v5.txt\n"
     ]
    }
   ],
   "source": [
    "def clean_and_rebuild_dataset_v5(positive_paths, negative_paths, output_file):\n",
    "    import random\n",
    "\n",
    "    def load_clean_reviews(paths):\n",
    "        reviews = []\n",
    "        for path in paths:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                for line in file:\n",
    "                    cleaned = preprocess_review(line)\n",
    "                    if cleaned:  # Keep only valid reviews\n",
    "                        reviews.append(cleaned)\n",
    "        return reviews\n",
    "\n",
    "    # Clean positive and negative reviews\n",
    "    print(\"Cleaning positive reviews...\")\n",
    "    positive_reviews = load_clean_reviews(positive_paths)\n",
    "    print(\"Cleaning negative reviews...\")\n",
    "    negative_reviews = load_clean_reviews(negative_paths)\n",
    "\n",
    "    # Combine and shuffle\n",
    "    print(\"Combining and shuffling reviews...\")\n",
    "    final_reviews = [(review, \"positive\") for review in positive_reviews] + \\\n",
    "                    [(review, \"negative\") for review in negative_reviews]\n",
    "    random.shuffle(final_reviews)\n",
    "\n",
    "    # Save to file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        for review, label in final_reviews:\n",
    "            file.write(f\"{label}\\t{review}\\n\")\n",
    "\n",
    "    print(f\"Final dataset saved to {output_file}\")\n",
    "\n",
    "# Define paths\n",
    "positive_paths = [\n",
    "    \"./domain_sentiment_data/sorted_data_acl/books/positive.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/electronics/positive.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/kitchen_&_housewares/positive.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/dvd/positive.review\",\n",
    "]\n",
    "\n",
    "negative_paths = [\n",
    "    \"./domain_sentiment_data/sorted_data_acl/books/negative.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/electronics/negative.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/kitchen_&_housewares/negative.review\",\n",
    "    \"./domain_sentiment_data/sorted_data_acl/dvd/negative.review\",\n",
    "]\n",
    "\n",
    "# Process and save\n",
    "clean_and_rebuild_dataset_v5(positive_paths, negative_paths, \"final_reviews_cleaned_v5.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QiDuQtUHroxK",
    "outputId": "edd52345-2160-4096-ef78-ba68e8604c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows of final_reviews_cleaned_v5.txt:\n",
      "positive\tcontrols takes getting used to\n",
      "positive\twe bought a model home for custom built homes and there was alot of heavy traffic foot in the house not to mention we have pets in the house\n",
      "negative\tfirst of all evolution in the sense of common descent is not impossible even idiot superstars michael behe stephen meyer and jonathan wells have admitted as much see a summary of their recent testimony in the kansas biology curriculum hearings in the evolutioncreationism forum at the west virginia gazette wvgazettemail put forums after com so any idiot who thinks all that bafflegab about irreducible complexity ic and the nonsense in this film is the death knell of evolution is simply ignorant  man evolved from nonhuman ancestors get over it\n",
      "negative\tapril 11 2006\n",
      "positive\tserge j van steenkiste\n",
      "negative\t2 of 4\n",
      "positive\tnovember 16 2006\n",
      "positive\tjuly 21 2006\n",
      "negative\ttheresa clare islandgrrrl\n",
      "negative\ti thought id come away with useful information\n",
      "negative\tdoes not do the book justice\n",
      "negative\toctober 1 2004\n",
      "positive\t9 of 9\n",
      "positive\twarning do not watch this movie if you are hungry if you do within the first 10 minutes you will pause it and have to run out for chinese food instantly and not the quick take out junk either but the honest to god traditional chinese cuisine that the father makes i adore this movie it is a heartwarming hilarious story about a widower retired master chef and his three very different daughters ang lee gives us insight into this family from the perspective of how love and life and humanity can be compared to eating and drinking the soundtrack is amazing the scenery is magnificent and the realness of it all transport you in so that you can almost smell the food cooking i would have killed to be on that set to just sample all those dishes\n",
      "positive\ti do not use all the functions that came with this mp3 player  it has music fm radio photo voice video and a settings option  i have used the music function and the voice recorder option both with good results  the only downside to the voice recorder is that you cant get the recordings you made off the mp3 player and onto your computer  it would have been nice to be able to record things and sync them onto your computer  as for syncing music files i have not had any problems although i did have one instance where it shows a song was downloaded but when you try to play it it skips to the next song alphabetically in the list  i dont know what caused this  also you can only store a song as one genre which is a little annoying  be sure you have your genres picked before you sync because once the song is on the mp3 player you cannot change the genre\n",
      "negative\tladder 49 widescreen edition dvd jay russelljoaquin phoenixjohn travoltajacinda barrettrobert patrickmorris chestnutbilly burkebalthazar gettytim guineekevin chapmanjay hernandezkevin danielssteve mayerobert lewis viiibrooke hamlinspencer berglundkaren vicksdesiree caredeidra lawan starnespeggy caffertymarja allen\n",
      "positive\tpny psd512rf 512mb sd secure digital flash memory card electronics\n",
      "negative\tjuly 2 2006\n",
      "negative\tthis is the first book ive ever returned while a lot of what she does is admirable and does work the you form instead of lordhe works very well two things make it unusable constant use of beloved for the word god or lord becomes irritating very quickly and she subjectively pops out the word enemies wherever it appears and puts in fears i wouldnt dare tell someone with aids or a refuge or whomever that their only enemy is their own fears and even for others such overpersonalization doesnt work the classic 137th psalm was unrecognizable  where did the dolphins come from\n",
      "negative\twhy are there so many insanely positive reviews for this book  honestly what has this author contributed to the world with this book  was it the characters  no theyve all been used and reused and used some more in practically every other work of fiction in the last fifty years ie cocky and handsome fbi agent beautiful but dangerous killer with a past takenosht fbi boss etc  was it the deep insight into the characters themselves  a laugh out loud no  there was nothing coming close to character development  was there some new and clever writing style  unless you count having two page chapters revolutionary i call it a way to have a two hundred page novella turned into a four hundred page novel  how about the plot  was that something worth my time  not unless you havent ever watched suspence movie in your life\n"
     ]
    }
   ],
   "source": [
    "print(\"First 20 rows of final_reviews_cleaned_v5.txt:\")\n",
    "with open(\"final_reviews_cleaned_v5.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i < 20:\n",
    "            print(line.strip())\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYdhZOsat5XG",
    "outputId": "4ea957e2-bf7f-42b9-e87d-10a9afa4b34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid line 1458: negative\t6\tthe next brother is sentenced to be suffocated  hes shovelled into an oven\n",
      "Skipping invalid line 1943: negative\t4\tvolume is a bit underpowered will not knock your socks off\n",
      "Skipping invalid line 3571: negative\tok i take my words back i found a solution to the connection problem with windows xp download a patch \twindowsxpkb884020x86enuexe solving wpa issues from microsoft then everything goes as it should be\n",
      "Skipping invalid line 4164: negative\t3\tthere is no support at all from the dlo website it just lets me download a pdf of the manual or to buy more accessories  i did not even bother contacting them due to all the problems   i am not impressed\n",
      "Skipping invalid line 5513: negative\t2\tnice look to the unit\n",
      "Skipping invalid line 8702: negative\t3\twelllit displays\n",
      "Skipping invalid line 10195: negative\t3\tcannot search the phonebook if you sorted it alphabetically and\n",
      "Skipping invalid line 10621: negative\t4\teasy to understand voice prompts when accessing remotely\n",
      "Skipping invalid line 10705: negative\t10\tmotorola customer support excellent\n",
      "Skipping invalid line 10776: negative\t4\tcant record an outgoing message remotely\n",
      "Skipping invalid line 11302: negative\t1\tthe sound quality is very poor  almost every song has some distortion and sounds muffled along with a good hiss  i thought i was listening to a 70s era cassette it was so bad  i have a high end sonyinfinity system and the poor sound is very noticeable  in desperation and checking to make sure my amp was working fine i plugged in my apple dock from my 4th gen photo 60gb and the standard apple av cable  the sound problem disappeared and was crystal clear\n",
      "Skipping invalid line 13817: negative\t3\tmissing mid tone satellites sound like they are coming out off a tin can\n",
      "Skipping invalid line 15070: negative\t5\tthe next brother is sentenced to be burned alive  he was tied up to a stake and set fire\n",
      "Skipping invalid line 16297: negative\t1\tgreat design and feel especially the handset\n",
      "Skipping invalid line 17764: negative\t1\tsatellites produce static noise even with the computer turned off you have to press the mute button to get rid of it\n",
      "Skipping invalid line 25610: negative\t1\teven at maximum volume you can barely hear the speakerphone on\n",
      "Skipping invalid line 25882: negative\t5\tbattery level indicator on handset is useless when the handset is\n",
      "Skipping invalid line 27267: negative\t4\tthere also all the other problems listed elsewhere too light and build quality poor annoying power led on front no artwork on tv menu etc\n",
      "Skipping invalid line 29296: negative\t2\tthe menus to not work properly  my nano 5gb seems to work ok but my 60gb 4th gen photo does not  the menus are rather slow and the artist or album or song titles disappear at random  sometimes you can back up a level on the menu and you will see the data but mostly it is just blank  the cursor will scroll down as though there is data there but nothing shows on the screen  you can play the music from the blank screen but it is pot luck as to what you will play as you cannot see any titles  i like the idea but very very frustrating\n",
      "Skipping invalid line 29691: positive\thal zina bennetts profound advice from his prolific writing career over 30 published books is quotwrite from the heartquot  as wonderful as that sounds most writers know its not an easy thing to do  \thal takes us to another dimension by sharing his personal process and showing each of us how we can remove the blocks to our expression and creativity by learning how to speak from our heart to the heart of our reader i can speak from my own personal experience having attended his workshops and received personal counselling from him in the process of writing my book quotsacred woman sacred dance  awakening spirituality through movement and ritualquot \tquotwrite from the heartquot also offers practical guidance in several areas  this includes such things as the need for solitude  however he is not just talking about having quota quiet spacequot he goes beyond the physical to the inner  a state of mind  he says quotonce we know what it is what it looks like and feels like we can create it for ourselves almosti say quotalmostquotregardless of where we happen to bequot  \ti would certainly recommend this book to anyone writing for personal expression or looking to be published\n",
      "Skipping invalid line 30666: negative\t4\tthe next brother was sentenced to be drowned and was thrown overboard from a boat\n",
      "Skipping invalid line 31523: negative\t2\textremely rumble base not crisp even turned all the way down it is too prominent maybe good for war games\n",
      "Skipping invalid line 33558: negative\t5\tso basically it is way too expensive  not worth it  not even worth 10 of the price charged\n",
      "Skipping invalid line 33993: negative\t2\tone brother is tried arrested and sentenced to have his head cut off\n",
      "Skipping invalid line 36095: negative\tpros \t great sound with other than manufacturer provided headphones\n",
      "Skipping invalid line 39375: negative\t9\tbase has phonebook that can be shared by the handsets\n",
      "Skipping invalid line 40233: negative\t2\tsound on the handset is distorted fuzzy the person on the other\n",
      "Skipping invalid line 41091: negative\t5\treasonable range\n",
      "Skipping invalid line 41922: negative\t6\tnice feel to the buttons\n",
      "Skipping invalid line 42320: positive\tlost world\t \t\t knopf inc 1995 hardback 393 pp 1887\n",
      "Skipping invalid line 44794: negative\t1\ta little boy drowns never to be seen again\n",
      "Skipping invalid line 46145: negative\t7\tfairly easy to go through the setup\n",
      "Skipping invalid line 47341: negative\t3\tthe people of the village assemble in the village to witness the execution where the executioner took his sword and struck a mighty blow\n",
      "Skipping invalid line 51208: positive\tmichael crichton\t\t                            isbn 0679419462\n",
      "Skipping invalid line 52452: negative\t8\tability to sort the phonebook alphabetically\n",
      "Cleaned dataset saved to D:/Intelligent System/Final_group_Assignment/final_reviews_cleaned_v5_fixed.txt\n"
     ]
    }
   ],
   "source": [
    "# Clean the file to ensure each line has exactly two fields\n",
    "cleaned_lines = []\n",
    "file_path = \"D:/Intelligent System/Final_group_Assignment/final_reviews_cleaned_v5.txt\"\n",
    "cleaned_file_path = \"D:/Intelligent System/Final_group_Assignment/final_reviews_cleaned_v5_fixed.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        # Split the line into fields based on tabs\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        if len(fields) == 2:  # Keep only valid lines\n",
    "            cleaned_lines.append(line)\n",
    "        else:\n",
    "            print(f\"Skipping invalid line {i + 1}: {line.strip()}\")\n",
    "\n",
    "# Save the cleaned dataset\n",
    "with open(cleaned_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.writelines(cleaned_lines)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qr_gX0pFuihd",
    "outputId": "d03d4f74-16ac-46da-acc5-83e512111681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                             review\n",
      "0  positive                     controls takes getting used to\n",
      "1  positive  we bought a model home for custom built homes ...\n",
      "2  negative  first of all evolution in the sense of common ...\n",
      "3  negative                                      april 11 2006\n",
      "4  positive                             serge j van steenkiste\n",
      "Dataset size: (53915, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reload the cleaned dataset\n",
    "data = pd.read_csv(\n",
    "    \"D:/Intelligent System/Final_group_Assignment/final_reviews_cleaned_v5_fixed.txt\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"label\", \"review\"]\n",
    ")\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n",
    "print(f\"Dataset size: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8snJsGtupo8",
    "outputId": "54e23f01-0286-4b6b-d37c-1a71372694dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                             review\n",
      "0      1                     controls takes getting used to\n",
      "1      1  we bought a model home for custom built homes ...\n",
      "2      0  first of all evolution in the sense of common ...\n",
      "3      0                                      april 11 2006\n",
      "4      1                             serge j van steenkiste\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"D:/Intelligent System/Final_group_Assignment/final_reviews_cleaned_v5_fixed.txt\"\n",
    "data = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"label\", \"review\"])\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to reviews\n",
    "data[\"review\"] = data[\"review\"].apply(preprocess_text)\n",
    "\n",
    "# Map labels to numerical values (encode labels)\n",
    "data[\"label\"] = data[\"label\"].map({\"positive\": 1, \"negative\": 0})\n",
    "\n",
    "# Display sample data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQjSEZQRu-6R",
    "outputId": "32120973-91c4-4a56-d31c-4168fc5d53cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after outlier removal: (29836, 2)\n"
     ]
    }
   ],
   "source": [
    "# Remove reviews with fewer than 5 words or more than 200 words\n",
    "data = data[data[\"review\"].apply(lambda x: 5 <= len(x.split()) <= 200)]\n",
    "\n",
    "# Display the shape of the dataset after outlier removal\n",
    "print(\"Dataset shape after outlier removal:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQrRGTw-vDsE",
    "outputId": "783fb5d8-1687-4ea6-9d52-68d284346c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample padded sequence: [2079  346  284  131    5    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenize the reviews\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data[\"review\"])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert reviews to sequences\n",
    "sequences = tokenizer.texts_to_sequences(data[\"review\"])\n",
    "\n",
    "# Pad or truncate the sequences to a fixed length\n",
    "max_length = 100  # Fixed length for all sequences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# Display sample padded data\n",
    "print(\"Sample padded sequence:\", padded_sequences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCmCPZpqvKEq",
    "outputId": "ca21ebc4-4ee9-49ac-81a6-b60ddcbf8e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (23868, 100)\n",
      "Validation set size: (2984, 100)\n",
      "Test set size: (2984, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define input (X) and output (y)\n",
    "X = padded_sequences\n",
    "y = data[\"label\"].values\n",
    "\n",
    "# Split into training (80%), validation (10%), and test (10%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display shapes of the splits\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BUndnKHvSS8",
    "outputId": "1d5a2e95-a2fe-4bd4-98f8-b5c071e6978d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 134ms/step - accuracy: 0.5015 - loss: 0.6939 - val_accuracy: 0.4946 - val_loss: 0.6932\n",
      "Epoch 2/5\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 126ms/step - accuracy: 0.5080 - loss: 0.6917 - val_accuracy: 0.5017 - val_loss: 0.6973\n",
      "Epoch 3/5\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 131ms/step - accuracy: 0.5162 - loss: 0.6767 - val_accuracy: 0.5111 - val_loss: 0.7060\n",
      "Epoch 4/5\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 130ms/step - accuracy: 0.5392 - loss: 0.6498 - val_accuracy: 0.5097 - val_loss: 0.7368\n",
      "Epoch 5/5\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 115ms/step - accuracy: 0.5446 - loss: 0.6414 - val_accuracy: 0.5097 - val_loss: 0.8045\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.5051 - loss: 0.8341\n",
      "Test Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=max_length),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation=\"sigmoid\")  # Binary classification (positive/negative)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HATwCVuhznJG",
    "outputId": "0edf1316-7ea0-4f91-83a3-f1cdde776604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    15037\n",
      "0    14799\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(data[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-R0bgWtGJJEr",
    "outputId": "b5fd845e-0545-4ce1-96c1-4d5cdec56ce9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Assuming 'model' is your trained LSTM model\n",
    "\n",
    "# Save the trained LSTM model\n",
    "model.save('sentiment_lstm_model.h5')  # This will save the model to a file\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9eHfgaqLR3i",
    "outputId": "91d91087-623d-44c7-d531-237474a011ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming 'tokenizer' is the tokenizer you used during training\n",
    "joblib.dump(tokenizer, 'tokenizer.pkl')  # Save the tokenizer to a file\n",
    "print(\"Tokenizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\python312\\lib\\site-packages (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\python312\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\python312\\lib\\site-packages (from ipywidgets) (8.26.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\python312\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in c:\\python312\\lib\\site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in c:\\python312\\lib\\site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: decorator in c:\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\python312\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\python312\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\python312\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\python312\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\python312\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python312\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191,
     "referenced_widgets": [
      "b1dbeb5538e54290812eca538ce95744",
      "5f3b1834d525486db092caa0f5df7df4",
      "5665d62c90d4443d8a2a570cd8288d53",
      "2ef4e34e53c9490b8b11f0a938ae6d5e",
      "d4a2cfe6618b4c69879ad7ca3ccfac47"
     ]
    },
    "id": "ENOQ5OfELe12",
    "outputId": "e9b76ec9-4a62-4108-d5fe-bcb0807a04cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30dbdcf68da94f7989d87983b2d572dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Review:', placeholder='Type a sentence here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c49d297729a420ba216a751c9f46f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b55959cc0c4b06bace1a29bb493883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Load the trained LSTM model\n",
    "model = load_model('sentiment_lstm_model.h5')\n",
    "\n",
    "# Load the saved tokenizer\n",
    "tokenizer = joblib.load('tokenizer.pkl')\n",
    "\n",
    "# Define MAX_SEQUENCE_LENGTH (same as used during training)\n",
    "MAX_SEQUENCE_LENGTH = 100  # Adjust to your training config\n",
    "\n",
    "# Define the prediction function\n",
    "def predict_sentiment(sentence):\n",
    "    # Preprocess the sentence using the same tokenizer and padding as during training\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])  # Convert sentence to token sequence\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)  # Pad the sequence to the correct length\n",
    "\n",
    "    # Predict sentiment using the LSTM model\n",
    "    prediction = model.predict(padded_sequence)\n",
    "\n",
    "    # If prediction > 0.5, consider it as Positive, else Negative\n",
    "    if prediction > 0.5:\n",
    "        return \"Positive Review\"\n",
    "    else:\n",
    "        return \"Negative Review\"\n",
    "\n",
    "# Create an input field for the user\n",
    "input_field = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type a sentence here',\n",
    "    description='Review:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Define an output widget to display the result\n",
    "output = widgets.Output()\n",
    "button = widgets.Button(description=\"Predict\")\n",
    "\n",
    "\n",
    "# Function to handle prediction and display result\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if input_field.value.strip():\n",
    "            prediction = predict_sentiment(input_field.value)\n",
    "            print(f\"Prediction: {prediction}\")\n",
    "        else:\n",
    "            print(\"Please enter a review.\")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the widgets\n",
    "display(input_field,button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2ef4e34e53c9490b8b11f0a938ae6d5e": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_d4a2cfe6618b4c69879ad7ca3ccfac47",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Input: THis book was horrible.  If it was possible to rate it lower than one star i would have.  I am an avid reader and picked this book up after my mom had gotten it from a friend.  I read half of it, suffering from a headache the entire time, and then got to the part about the relationship the 13 year old boy had with a 33 year old man and i lit this book on fire.  One less copy in the world...don't waste your money.\n"
        ]
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step"
        ]
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n"
        ]
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Prediction: Negative Review\n"
        ]
       }
      ]
     }
    },
    "5665d62c90d4443d8a2a570cd8288d53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f3b1834d525486db092caa0f5df7df4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1dbeb5538e54290812eca538ce95744": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Review:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_5f3b1834d525486db092caa0f5df7df4",
      "placeholder": "Type a sentence here",
      "style": "IPY_MODEL_5665d62c90d4443d8a2a570cd8288d53",
      "value": "THis book was horrible.  If it was possible to rate it lower than one star i would have.  I am an avid reader and picked this book up after my mom had gotten it from a friend.  I read half of it, suffering from a headache the entire time, and then got to the part about the relationship the 13 year old boy had with a 33 year old man and i lit this book on fire.  One less copy in the world...don't waste your money."
     }
    },
    "d4a2cfe6618b4c69879ad7ca3ccfac47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
